{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO92OF0h0FsW0QTTadOiw0m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elektromusik/RAG/blob/main/RAG_with_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG with Metadata."
      ],
      "metadata": {
        "id": "ljEqpEapKaUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Packages."
      ],
      "metadata": {
        "id": "-vuyBztpIzt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --quiet install faiss-cpu langchain langchain_community langchain_mistralai\n",
        "!pip --quiet install pypdf sentence_transformers\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ],
      "metadata": {
        "id": "diYSsATQZjhB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing."
      ],
      "metadata": {
        "id": "cJtCZCx8I7FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the .pdf Documents. Adjust the page numbers.\n",
        "loader = PyPDFDirectoryLoader(\"/content/\", glob=\"*.pdf\")\n",
        "pages = loader.load()\n",
        "[page.metadata.update({\"page\": page.metadata[\"page\"] + 1}) for page in pages]\n",
        "\n",
        "# Choose the Chunk Size.\n",
        "# [1 chunk has at most 256 words (exceeding words are truncated due to the\n",
        "# embedding model). 1 word in English language has 4.7 characters on average.\n",
        "# Hence, 1 chunk has at most about 1000 characters. Further, 1 page has\n",
        "# around 700 words. Alltogether, we end up with at least 3 chunks per page at\n",
        "# a chunk_size of 1000.]\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "                              chunk_size    =1000,\n",
        "                              chunk_overlap = 100,\n",
        "                              separators = [\"\\n\\n\", \"\\n\", \".\", \",\", \" \", \"\"])\n",
        "\n",
        "# Create the chunks.\n",
        "chunks = [{\"chunk_content\" : text_splitter.split_text(pages[i].page_content),\n",
        "           \"metadata\" : pages[i].metadata} for i in range(len(pages))]\n",
        "\n",
        "# Create Langchain Documents.\n",
        "Documents = [Document(page_content=text, metadata=chunk['metadata'])\n",
        "             for chunk in chunks for text in chunk['chunk_content']]\n",
        "\n",
        "# Check the metadata.\n",
        "[print(Document.metadata) for Document in Documents[:15] + Documents[-15:]]\n",
        "\n",
        "# Choose the Embedding Model.\n",
        "# [I tried to find the best embedding model via the MTEB leaderboard at\n",
        "# huggingface.co:\n",
        "# 1) nvidia/NV-Embed-v2 (not found on NVIDIA website),\n",
        "# 2) BAAI/bge-en-icl (runs forever)],\n",
        "# ...\n",
        "# 10) nvidia/NV-Embed-v1 (packages incompatible).\n",
        "# Hence, I ended up with the following standard model. The problem with this\n",
        "# model is, that it truncates above 257 words ~ 1000 characters.]\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Add the Chunks and the Metadata to the Vector Database.\n",
        "vectorstore = FAISS.from_documents(documents=Documents,\n",
        "                                   embedding=embedding_model)"
      ],
      "metadata": {
        "id": "9z-4QXRkb5V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5067a046-3c4c-4157-adc9-7a36f049a82f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 1}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 1}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 1}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 1}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 1}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 2}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 2}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 2}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 2}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 2}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 3}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 3}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 3}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 3}\n",
            "{'source': '/content/The_Great_Gatsby_Part_1.pdf', 'page': 4}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 46}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 47}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 47}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 47}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 47}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 48}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 48}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 48}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 48}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 49}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 49}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 49}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 49}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 50}\n",
            "{'source': '/content/The_Great_Gatsby_Part_2.pdf', 'page': 50}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Components of RAG."
      ],
      "metadata": {
        "id": "TbmITKZoJI5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retriever.\n",
        "# [Similarity search with a threshold: search_type=\"similarity_score_threshold\",\n",
        "# search_kwargs={\"score_threshold\": 0.05}]\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Systemprompt.\n",
        "template = \"\"\"\n",
        "You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context:  {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Set LLM.\n",
        "llm = ChatMistralAI(mistral_api_key=YOUR_API_KEY)\n",
        "\n",
        "# Create Pipeline (Retrieve-Augment-Generate)\n",
        "RAG_chain = ({\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
        "              | prompt\n",
        "              | llm\n",
        "              | StrOutputParser())"
      ],
      "metadata": {
        "id": "cRZpR1VvJgzq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q&A."
      ],
      "metadata": {
        "id": "6-UOB5h4KLP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate\n",
        "query = \"\"\"Who was invited to the parties? On which pages are they listed?\"\"\"\n",
        "RAG_chain.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "tpM1u6TGGuoF",
        "outputId": "7058c57b-471c-4343-8dea-8038515768b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The individuals who were invited to Gatsby's parties include Nick Carraway, as mentioned on page 21 of the first document. Other people were not specifically invited and simply forced their way in, as stated on page 24 of the first document. A woman named Roosevelt also brought someone to Gatsby's house, as mentioned on page 24 of the first document.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rBs8FqlNDGAE"
      }
    }
  ]
}
